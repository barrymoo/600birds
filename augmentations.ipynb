{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import audio\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunk extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function: `wraparound_extract()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wraparound_extract(original, begin, length):\n",
    "    '''\n",
    "    Extracts elements from numpy.array in a \"wraparound\" fashion\n",
    "    \n",
    "    Extracts a certain number of elements from \n",
    "    a numpy.array starting at a certain position.\n",
    "    If the chosen position and length go\n",
    "    past the end of the array, the extraction\n",
    "    \"wraps around\" to the beginning of the numpy.array\n",
    "    as many times as necessary. For instance:\n",
    "    \n",
    "    wraparound_extract(\n",
    "        original = [0, 5, 10],\n",
    "        begin = 1, \n",
    "        length = 7) -> [5, 10, 0, 5, 10, 0, 5]\n",
    "    \n",
    "    Args:\n",
    "        original (np.array): the original array \n",
    "        begin (int): beginning position to extract\n",
    "        length (int): number of elements to extract\n",
    "    '''\n",
    "\n",
    "    # Get `head`: the array after the beginning position\n",
    "    assert(type(original) == np.ndarray)\n",
    "    len_original = original.shape[0]\n",
    "    begin = begin % len_original\n",
    "    head = original[begin:]\n",
    "    len_head = head.shape[0]\n",
    "\n",
    "    # Number of elements we require for full wrap-around\n",
    "    wrap_needed = length - len_head\n",
    "\n",
    "    # Generate the desired list, wrapped if necessary\n",
    "    if wrap_needed > 0:\n",
    "        repeats = np.tile(original, int(wrap_needed/len_original))\n",
    "        tail = np.array(original[ : (wrap_needed % len_original)])\n",
    "        desired_list = np.concatenate((head, repeats, tail))\n",
    "    else:\n",
    "        desired_list = original[begin:begin+length]\n",
    "    \n",
    "    #print(desired_list)\n",
    "    return desired_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.testing as npt\n",
    "\n",
    "# test zero beginning, not getting to end of original array\n",
    "npt.assert_array_equal(wraparound_extract(original = np.array([0, 1]), begin = 0, length = 1), np.array([0]))\n",
    "\n",
    "# test zero beginning, not getting to end of original array\n",
    "npt.assert_array_equal(wraparound_extract(original = np.array([0, 1]), begin = 0, length = 2), np.array([0, 1]))\n",
    "\n",
    "# test zero beginning, not wrapping\n",
    "npt.assert_array_equal(wraparound_extract(original = np.array([0, 1]), begin = 0, length = 2), np.array([0, 1]))\n",
    "\n",
    "# test zero beginning, wrapping around\n",
    "npt.assert_array_equal(wraparound_extract(original = np.array([0, 1]), begin = 0, length = 3), np.array([0, 1, 0]))\n",
    "\n",
    "# test nonzero beginning, not wrapping\n",
    "npt.assert_array_equal(wraparound_extract(original = np.array([0, 1]), begin = 1, length = 1), np.array([1]))\n",
    "\n",
    "# test nonzero beginning, wrapping around\n",
    "npt.assert_array_equal(wraparound_extract(original = np.array([0, 1]), begin = 1, length = 3), np.array([1, 0, 1]))\n",
    "\n",
    "# test multiwrap\n",
    "npt.assert_array_equal(wraparound_extract(original = np.array([0, 1]), begin = 1, length = 10), np.array([1, 0, 1, 0, 1, 0, 1, 0, 1, 0]))\n",
    "\n",
    "# test wrapping around beginning\n",
    "npt.assert_array_equal(wraparound_extract(original = np.array([0, 1]), begin = 5, length = 3), np.array([1, 0, 1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main function: `get_chunk()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.0228204e-05, -5.9536369e-06,  1.8859782e-05, ...,\n",
       "        8.7023282e-06, -9.8293631e-06, -9.2994751e-06], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_chunk(\n",
    "    samples, \n",
    "    sample_rate,\n",
    "    start_position = None, # randomize start position\n",
    "    duration = 5, # 5 seconds\n",
    "    duration_jitter = 0.5, #jitter duration +- 0.5s\n",
    "    chance_random_skip = 0.3 #randomly skip 30% of the time\n",
    "):\n",
    "    '''\n",
    "    Extracts chunk of audio with some augmentation\n",
    "    \n",
    "    Extracts samples of audio from a master list\n",
    "    of samples. \n",
    "    \n",
    "    Available data augmentation options include:\n",
    "        - selecting a position to start extracting from\n",
    "          or allowing function to randomly choose start\n",
    "        - selecting duration of chunk and allowing\n",
    "          for random jitter of duration\n",
    "        - randomly skipping some number of samples from\n",
    "          0 to the length of the chunk\n",
    "    \n",
    "    If the chunk to be extracted reaches the end of the\n",
    "    samples, the chunk will \"wrap around\" and start\n",
    "    reading from the beginning of the samples.\n",
    "    \n",
    "    Args:\n",
    "        samples (numpy.array): audio samples loaded\n",
    "            by librosa.load or audio.load\n",
    "        sample_rate (int or float): sample rate of `samples`\n",
    "        start_position (int): position in the file to start\n",
    "            extracting samples from. If None, the start position \n",
    "            is chosen randomly\n",
    "        duration (float): desired duration, in seconds, \n",
    "            of chunk to extract\n",
    "        duration_jitter (float): if this value is not 0,\n",
    "            the duration of the chunk extracted will \n",
    "            be randomly selected from the range \n",
    "            (duration - duration_jitter, duration + duration_jitter)\n",
    "        chance_random_skip (float between 0 and 1):\n",
    "            percent chance of random skipping. In a random skip,\n",
    "            a position within the chunk will be randomly\n",
    "            selected, and from that position in the \n",
    "            audio file, a random number of samples will \n",
    "            be skipped. The number of samples skipped is between\n",
    "            0 and the number of samples in the entire chunk\n",
    "    \n",
    "    Returns:\n",
    "        samples\n",
    "    '''\n",
    "    \n",
    "    # Get a random start position\n",
    "    num_samples = len(samples)\n",
    "    if not start_position:\n",
    "        start_position = random.randint(0, num_samples)\n",
    "\n",
    "    # Convert seconds to samples\n",
    "    seconds_to_extract = duration + random.uniform(-duration_jitter, duration_jitter)\n",
    "    samples_to_extract = int(seconds_to_extract * sample_rate)\n",
    "    \n",
    "    # Get chunks with skip in the middle with probability = chance_random_skip\n",
    "    if random.random() < chance_random_skip:\n",
    "        position_to_skip = random.randint(0, samples_to_extract)\n",
    "        amount_to_skip = random.randint(0, samples_to_extract)\n",
    "\n",
    "        chunk_1_start = start_position\n",
    "        chunk_1_end = chunk_1_start + position_to_skip\n",
    "        chunk_2_start = chunk_1_end + amount_to_skip\n",
    "        chunk_2_end = chunk_1_start + (samples_to_extract - position_to_skip)\n",
    "        \n",
    "        chunk_1 = wraparound_extract(samples, chunk_1_start, chunk_1_end)\n",
    "        chunk_2 = wraparound_extract(samples, chunk_2_start, chunk_2_end)\n",
    "        chunk = np.concatenate((chunk_1, chunk_2))\n",
    "    \n",
    "    # Otherwise get contiguous chunk\n",
    "    else:\n",
    "        chunk = wraparound_extract(samples, start_position, samples_to_extract) \n",
    "        \n",
    "    \n",
    "    return chunk\n",
    "    \n",
    "samples, sr = librosa.load('../tests/silence_10s.mp3')\n",
    "get_chunk(samples = samples, sample_rate = sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: tests for `get_chunk()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cyclic shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cyclic_shift(array, split_point = None):\n",
    "    '''\n",
    "    Shift array cyclicly by a random amount\n",
    "    \n",
    "    Shift array cyclicly by a random amount. Equivalent to\n",
    "    splitting array into two parts at a random element, then\n",
    "    switching the order of the parts.\n",
    "    \n",
    "    Args: \n",
    "        array (np.array): 1D-array to be split\n",
    "        split_point (float): percentage from (0, 1) describing\n",
    "            where in array to split -- for testing purposes.\n",
    "            For stochastic splitting, leave as None.\n",
    "    \n",
    "    Returns:\n",
    "        shifted_array: shifted array\n",
    "    '''\n",
    "    \n",
    "    assert(type(array) == np.ndarray)\n",
    "    length = array.shape[0]\n",
    "    \n",
    "    # Stochastic split point, or split point by floor of split_point * length of array\n",
    "    if not split_point: split_point = random.randint(0, length)\n",
    "    else: split_point = int(split_point * length)\n",
    "    \n",
    "    return np.concatenate((array[split_point:], array[:split_point]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test random splitting\n",
    "random.seed(100)\n",
    "npt.assert_array_equal(cyclic_shift(np.array((0, 1, 2, 3, 4, 5, 6, 7))), np.array([2, 3, 4, 5, 6, 7, 0, 1]))\n",
    "\n",
    "# Test deterministic splitting\n",
    "npt.assert_array_equal(cyclic_shift(np.array([0, 1, 2]), split_point=0.5), np.array([1, 2, 0]))\n",
    "\n",
    "# Test deterministic splitting\n",
    "npt.assert_array_equal(cyclic_shift(np.array([0, 1, 2, 3]), split_point=0.5), np.array([2, 3, 0, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divided-samples augmentations: time & freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function to divide samples randomly: `divide_samples()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_samples(\n",
    "    samples,\n",
    "    sample_rate,\n",
    "    low_duration = 0.5,\n",
    "    high_duration = 5\n",
    "):\n",
    "    '''\n",
    "    Divide audio samples into random-sized segments\n",
    "    \n",
    "    Divide audio samples into random-sized segments\n",
    "    between the desired durations. The number\n",
    "    of segments is not deterministic.\n",
    "    \n",
    "    Args:\n",
    "        samples (np.ndarray): 1d array of samples\n",
    "        sample_rate (int or float): sample rate of samples\n",
    "        low_duration (float): minimum duration\n",
    "            in seconds of any segment\n",
    "        high_duration (float): maximum duration\n",
    "            in seconds of any segment\n",
    "    \n",
    "    Returns:\n",
    "        segments, list of sample lists\n",
    "    '''\n",
    "    \n",
    "    min_chunk = int(low_duration * sample_rate)\n",
    "    max_chunk = int(high_duration * sample_rate)\n",
    "    \n",
    "    samples_to_take = samples.copy()\n",
    "    \n",
    "    segments = []\n",
    "    \n",
    "    while samples_to_take.shape[0]:\n",
    "        seg_size = random.randint(min_chunk, max_chunk)\n",
    "        segment, samples_to_take = np.split(samples_to_take, [seg_size])\n",
    "        segments.append(segment)\n",
    "    \n",
    "    return segments\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test chunk division at set amount\n",
    "array0 = np.array([0, 0, 0])\n",
    "array1 = np.array([1, 1, 1])\n",
    "array2 = np.array([2])\n",
    "all_arrays = (array0, array1, array2)\n",
    "cat_arrays = np.concatenate(all_arrays)\n",
    "results = divide_samples(cat_arrays, sample_rate=1, low_duration=3, high_duration=3)\n",
    "for idx, result in enumerate(results):\n",
    "    npt.assert_array_equal(result, all_arrays[idx])\n",
    "    \n",
    "# Test random chunk division\n",
    "random.seed(333)\n",
    "# Predetermined results with random.seed(333)\n",
    "predetermined = [np.array([0, 1, 2, 3, 4, 5, 6, 7]), np.array([8, 9])]\n",
    "results = divide_samples(np.array(range(10)), sample_rate=1, low_duration=0, high_duration=10)\n",
    "for idx, result in enumerate(results):\n",
    "    npt.assert_array_equal(result, predetermined[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function to concatenate divisions: `combine_samples()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_samples(divided):\n",
    "    '''\n",
    "    Recombine divided sample arrays\n",
    "    \n",
    "    Combine divided sample arrays back into a \n",
    "    single array, perhaps after each division\n",
    "    has been modified by pitch shifting, time stretching, etc.\n",
    "    \n",
    "    Args:\n",
    "        divided (list of np.ndarrays): list of sample arrays\n",
    "            divided by divide_samples()\n",
    "    \n",
    "    Returns:\n",
    "        sample arrays concatenated back into a single array\n",
    "    '''\n",
    "    \n",
    "    return np.concatenate(divided)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test that divided samples can be recombined successfully\n",
    "samples, sr = librosa.load('../tests/silence_10s.mp3')\n",
    "divided = divide_samples(samples, sample_rate=sr, low_duration=0.5, high_duration=4)\n",
    "npt.assert_array_equal(combine_samples(divided), samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time stretch the divisions: `time_stretch_divisions()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_stretch_divisions(\n",
    "    divisions,\n",
    "    chance_per_division = 0.50,\n",
    "    mean_stretch = 1,\n",
    "    sd_stretch = 0.05\n",
    "):\n",
    "    '''\n",
    "    Time stretch divisions\n",
    "    \n",
    "    Given a list of np.ndarrays, each np.ndarray representing\n",
    "    audio samples, time stretch each array with some probability. \n",
    "    \n",
    "    Args\"\n",
    "        divisions (list of np.ndarrays): list of np.ndarrays\n",
    "            where each element of the list is samples from\n",
    "            an audio file. A list of divisions can be generated \n",
    "            with helper functions in this module\n",
    "        chance_per_division (float between 0 and 1): for\n",
    "            each division, the chance it will be time-stretched\n",
    "        mean_stretch (float): the mean stretch multiplier.\n",
    "            == 1 is no stretch; > 1 is sped up, < 1 is slowed down\n",
    "        sd_stretch (float > 0): the sd of the stretch \n",
    "            distribution. \n",
    "    \n",
    "    Returns:\n",
    "        stretched_divisions, time-stretched divisions\n",
    "    '''\n",
    "    stretched_divisions = []\n",
    "    \n",
    "    for d in divisions:\n",
    "        if random.random() < chance_per_division:\n",
    "            stretch_factor = np.random.normal(\n",
    "                loc = mean_stretch,\n",
    "                scale = sd_stretch)\n",
    "            stretched_d = librosa.effects.time_stretch(y = d, rate = stretch_factor)\n",
    "            stretched_divisions.append(stretched_d)\n",
    "        else:\n",
    "            stretched_divisions.append(d)\n",
    "    \n",
    "    return stretched_divisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predetermined results with random.seed(333)\n",
    "#predetermined = [np.array([0., 0.1, -0.1, 0.2, -0.2, 0.3, -0.3, 7]), np.array([8, 9])]\n",
    "random.seed(3)\n",
    "divs = divide_samples(np.linspace(0, 1, 10), sample_rate=1, low_duration=0, high_duration=10)\n",
    "np.random.seed(111)\n",
    "results = time_stretch_divisions(divs)\n",
    "\n",
    "# predetermined results for random.seed == 3 and np.random.seed == 111\n",
    "# np.random.seed must be set because randomness in time_stretch_divisions\n",
    "# comes from np.random.normal\n",
    "predetermined = [\n",
    "    np.array([0.        , 0.11111111, 0.22222222]),\n",
    "    np.array([0.27306482, 0.36267295, 0.45205913, 0.54126718,\n",
    "           0.63025186, 0.71660051, 0.80273002])\n",
    "]\n",
    "\n",
    "for idx, result in enumerate(results):\n",
    "    npt.assert_array_almost_equal(result, predetermined[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency shift the divisions: `pitch_shift_divisions()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pitch_shift_divisions(\n",
    "    divisions,\n",
    "    sample_rate,\n",
    "    chance_per_division = 0.40,\n",
    "    mean_shift = 0,\n",
    "    sd_shift = 0.25\n",
    "):\n",
    "    '''\n",
    "    Time stretch divisions\n",
    "    \n",
    "    Given a list of np.ndarrays, each np.ndarray representing\n",
    "    audio samples, pitch-shift each array with some probability. \n",
    "    The mean_shift and sd_shift should be given in \"fractional\n",
    "    half-steps,\" e.g. 0.25 = 1/4th of a half-step = 25 cents.\n",
    "    \n",
    "    Args:\n",
    "        divisions (list of np.ndarrays): list of np.ndarrays\n",
    "            where each element of the list is samples from\n",
    "            an audio file. A list of divisions can be generated \n",
    "            with helper functions in this module\n",
    "        sample_rate (int or float): sample rate of all divisions\n",
    "        chance_per_division (float between 0 and 1): for\n",
    "            each division, the chance it will be time-stretched\n",
    "        mean_shift (float): the mean pitch shift in (fractional) half-steps\n",
    "            == 0 is no shift; > 0 is shift up; < 1 is shift down\n",
    "        sd_shift (float > 0): the sd of the shift \n",
    "            distribution in cents\n",
    "    \n",
    "    Returns:\n",
    "        shifted_divisions, pitch-shifted divisions\n",
    "    '''\n",
    "    shifted_divisions = []\n",
    "    \n",
    "    for d in divisions:\n",
    "        if random.random() < chance_per_division:\n",
    "            shift_factor = np.random.normal(\n",
    "                loc = mean_shift,\n",
    "                scale = sd_shift)\n",
    "            shifted_d = librosa.effects.pitch_shift(\n",
    "                y = d,\n",
    "                sr = sample_rate,\n",
    "                n_steps = shift_factor)\n",
    "            shifted_divisions.append(shifted_d)\n",
    "        else:\n",
    "            shifted_divisions.append(d)\n",
    "    \n",
    "    return shifted_divisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-3.1739323e-06, -1.4155360e-05, -8.0013604e-07, ...,\n",
      "        1.8794424e-06,  7.1658078e-06, -4.9842856e-06], dtype=float32), array([ 3.5037613e-06, -3.3692386e-06,  6.0074067e-06, ...,\n",
      "        3.2044059e-05, -1.1334268e-05,  2.3847722e-05], dtype=float32), array([-5.5799287e-06, -9.8192986e-06,  2.4171062e-05, ...,\n",
      "        1.2083449e-05,  4.3980071e-06,  5.0061476e-06], dtype=float32), array([ 1.5683046e-06,  3.5010305e-06, -1.2555935e-05, ...,\n",
      "        6.1320316e-06, -1.4582495e-06, -1.5945519e-05], dtype=float32), array([ 2.0357647e-05, -5.1009292e-06,  1.6706794e-05, ...,\n",
      "        2.3299851e-06, -1.1209999e-06, -1.9890509e-05], dtype=float32)]\n",
      "\n",
      "[array([-3.7917514e-06, -1.3651467e-05, -1.0827831e-06, ...,\n",
      "        1.1708037e-05,  7.8524317e-07,  0.0000000e+00], dtype=float32), array([ 3.2972698e-06, -3.0527028e-06,  5.5270198e-06, ...,\n",
      "        2.5871668e-06,  8.6151454e-07,  0.0000000e+00], dtype=float32), array([-5.5799287e-06, -9.8192986e-06,  2.4171062e-05, ...,\n",
      "        1.2083449e-05,  4.3980071e-06,  5.0061476e-06], dtype=float32), array([ 1.5683046e-06,  3.5010305e-06, -1.2555935e-05, ...,\n",
      "        6.1320316e-06, -1.4582495e-06, -1.5945519e-05], dtype=float32), array([ 2.0357647e-05, -5.1009292e-06,  1.6706794e-05, ...,\n",
      "        2.3299851e-06, -1.1209999e-06, -1.9890509e-05], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "divs = divide_samples(\n",
    "    samples = samples,\n",
    "    sample_rate = sr,\n",
    "    low_duration = 0.5,\n",
    "    high_duration = 4)\n",
    "print(divs)\n",
    "print()\n",
    "print(pitch_shift_divisions(divs, sample_rate = sr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random audio filtering: `random_filter()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter, lfilter\n",
    "def random_filter(\n",
    "    samples,\n",
    "    sample_rate,\n",
    "    percent_chance = 0.20,\n",
    "    filter_type = None,\n",
    "    filter_order = None,\n",
    "    filter_low = None,\n",
    "    filter_high = None,\n",
    "    error_check = True\n",
    "):\n",
    "    '''\n",
    "    Randomly filter audio samples\n",
    "    \n",
    "    With some probability, apply a filter to `samples`. \n",
    "    Some or all of the filter's characteristics can be \n",
    "    provided by the user; otherwise, they are\n",
    "    are randomly selected from the following options:\n",
    "    \n",
    "    Type: lowpass, highpass, bandpass, bandstop\n",
    "    Order: 1-5\n",
    "    Low cutoff frequency: from 1Hz to (sample_rate/2) - 1 Hz\n",
    "    High cutoff frequency (bandpass \n",
    "        and bandstop filters): from low_freq+1 \n",
    "        to (sample_rate/2) - 1 Hz\n",
    "        \n",
    "    If filter output contains values not between -1.0 and 1.0,\n",
    "    the original signal is returned to avoid glitchy filters.\n",
    "    '''\n",
    "    \n",
    "    if random.random() < percent_chance:\n",
    "        \n",
    "        # Nyquist frequency\n",
    "        nyq = 0.5 * sample_rate\n",
    "        \n",
    "        # Select random filter choices\n",
    "        if not filter_type: filter_type = random.choice(\n",
    "            ['lowpass', 'highpass', 'bandpass', 'bandstop'])\n",
    "        if not filter_order: filter_order = random.randint(1, 5)\n",
    "        if not filter_low: filter_low = random.randint(1, (nyq - 1))\n",
    "        if not filter_high:\n",
    "            if filter_type in ['bandpass', 'bandstop']:\n",
    "                filter_high = random.randint(filter_low, nyq - 1)\n",
    "            else:\n",
    "                filter_high = nyq - 1\n",
    "        \n",
    "\n",
    "        # Filter the audio\n",
    "        low = filter_low / nyq\n",
    "        high = filter_high / nyq\n",
    "        b, a = butter(filter_order, [low, high], btype='band')\n",
    "        filtered = lfilter(b, a, samples)\n",
    "\n",
    "         # Error check filtered audio\n",
    "        if error_check:\n",
    "            if  np.less(filtered, -1, where=~np.isnan(filtered)).any() or \\\n",
    "                np.greater(filtered, 1, where=~np.isnan(filtered)).any():\n",
    "                return samples\n",
    "                # For debugging\n",
    "                #return samples, filtered, [filter_type, filter_order, filter_low, filter_high]\n",
    "            else:\n",
    "                return filtered\n",
    "                # For debugging\n",
    "                #return filtered, filtered, [filter_type, filter_order, filter_low, filter_high]\n",
    "        else:\n",
    "            return filtered\n",
    "    \n",
    "    else: return samples\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfiltered, sample_rate = librosa.load('../tests/1min.wav')\n",
    "\n",
    "# This filter will produce an invalid output \n",
    "# i.e., the array will contain values above 1\n",
    "filtered_not_checked = random_filter(\n",
    "    unfiltered, sample_rate, percent_chance=1,\n",
    "    filter_type = 'highpass',\n",
    "    filter_order = 5,\n",
    "    filter_low = 2690,\n",
    "    filter_high = 11024.0,\n",
    "    error_check = False\n",
    ")\n",
    "assert((filtered_not_checked > 1).any())\n",
    "\n",
    "# The same filter as above, but with error checking: \n",
    "# the error check should flag the invalid content\n",
    "# in the filtered result and return the original array\n",
    "filtered_checked = random_filter(\n",
    "    unfiltered, sample_rate, percent_chance=1,\n",
    "    filter_type = 'highpass',\n",
    "    filter_order = 5,\n",
    "    filter_low = 2690,\n",
    "    filter_high = 11024.0,\n",
    "    #error_check = True # Error checking by default\n",
    ")\n",
    "assert(~(filtered_checked > 1).any())\n",
    "assert(filtered_checked is unfiltered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding audio chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function, fade audio in or out: `fade()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fade(array, fade_len, start_amp=1):\n",
    "    '''\n",
    "    Fade audio in or out\n",
    "    \n",
    "    Args:\n",
    "        array (np.array): 1d audio array to fade\n",
    "            in or out\n",
    "        fade_len (int): the number of samples over which\n",
    "            the fade should occur; must be smaller than \n",
    "            array.shape[0]\n",
    "        start_amp (int, 1 or 0): whether to start at full \n",
    "            volume and fade out (1) or start at\n",
    "            0 volume and fade in (0)\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    if not ((start_amp is 0) or (start_amp is 1)):\n",
    "        raise ValueError('start_amp must be either 0 or 1') from None\n",
    "    \n",
    "    pad_len = int(array.shape[0] - fade_len)\n",
    "    if pad_len < 0:\n",
    "        raise IndexError('fade_len is longer than the number of samples in array') from None\n",
    "    \n",
    "    # Construct fade filter\n",
    "    #fade_filter = np.linspace(start_amp, int(not start_amp), fade_len)\n",
    "    # If fade_len is 1 and start_amp is 1, the above code results in \n",
    "    # a fade_filter = np.array([1.]), i.e. no fading. The below code\n",
    "    # ensures that the end amplitude is included\n",
    "    fade_filter = np.flip(np.linspace(int(not start_amp), start_amp, fade_len))\n",
    "    \n",
    "    # Pad filter for array length\n",
    "    if start_amp == 0: # fade in at start\n",
    "        fade_filter_padded = np.pad(\n",
    "            fade_filter,\n",
    "            (0, pad_len), # pad right side\n",
    "            constant_values = 1 # with 1s\n",
    "        )\n",
    "    else: # start_amp == 1, fade out at end\n",
    "        fade_filter_padded = np.pad(\n",
    "            fade_filter,\n",
    "            (pad_len, 0), # pad left side\n",
    "            constant_values = 1 # with 1s\n",
    "        )\n",
    "    return np.multiply(array, fade_filter_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "# Assert that fading out doesn't work if fade_len is too long\n",
    "with pytest.raises(IndexError):\n",
    "    fade(array = np.array((1, 1, 1, 1, 1)), fade_len=6, start_amp=1)\n",
    "    \n",
    "# Assert that can only provide 0 or 1 as start_amp\n",
    "with pytest.raises(ValueError):\n",
    "    fade(array = np.array((1, 1, 1)), fade_len=3, start_amp=1.0)\n",
    "with pytest.raises(ValueError):\n",
    "    fade(array = np.array((1, 1, 1)), fade_len=3, start_amp=True)\n",
    "    \n",
    "# Fade in on exactly correct length array\n",
    "fade_in = fade(array = np.array((1, 1, 1, 1, 1)), fade_len=5, start_amp=0)\n",
    "npt.assert_array_equal(fade_in, np.array([0., 0.25, 0.5, 0.75, 1.]))\n",
    "\n",
    "# Fade out on long array\n",
    "fade_out = fade(array = np.array((1, 1, 1, 1, 1, 1, 1)), fade_len=5, start_amp=1)\n",
    "npt.assert_array_equal(fade_out, np.array([1., 1., 1., 0.75, 0.5, 0.25, 0.]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function, pairwise sample summer: `sum_samples()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def sum_samples(\n",
    "    samples_original,\n",
    "    samples_new,\n",
    "    sample_rate,\n",
    "    wraparound_fill = False,\n",
    "    fade_out = True\n",
    "):\n",
    "    '''\n",
    "    Sums audio samples and updates labels\n",
    "    \n",
    "    Combines audio samples, samples_new, on top\n",
    "    of samples_original, overlaying samples_new\n",
    "    so it begins at the same time as samples_original.\n",
    "    \n",
    "    Args:\n",
    "        samples_original (np.array): samples to \n",
    "            overlay new samples on\n",
    "        samples_new (np.array): samples to be\n",
    "            overlayed on original samples. If shorter\n",
    "            than samples_original, can either be repeated/\n",
    "            wrapped around to reach length of\n",
    "            samples_original, or can be faded out\n",
    "        sample_rate (int or float): mutual sample rate\n",
    "            of both samples_original and samples_new\n",
    "        wraparound_fill (bool): whether or not to \n",
    "            fill in short samples_new by wrapping around\n",
    "        fade_out (bool): whether or not to fade out \n",
    "            short samples_new. If wraparound_fill == True,\n",
    "            this option does not apply.\n",
    "            \n",
    "    Returns:\n",
    "        summed samples\n",
    "    '''\n",
    "    \n",
    "    original_len = samples_original.shape[0]\n",
    "    new_len = samples_new.shape[0]\n",
    "    discrepancy = original_len - new_len\n",
    "    \n",
    "    # Add new samples to original samples, possibly applying \n",
    "    # fade-out, filling, etc.\n",
    "    if discrepancy > 0: # if new_len shorter than original_len\n",
    "        # Make up length by repeating/\"wrapping around\"\n",
    "        if wraparound_fill:\n",
    "            samples_to_add = wraparound_extract(\n",
    "                original = samples_new,\n",
    "                begin = 0,\n",
    "                length = original_len)\n",
    "        \n",
    "        # Make up length with zero-padding\n",
    "        else:\n",
    "            samples_to_add = samples_new.copy()\n",
    "            if fade_out:\n",
    "                # Number of samples used in fade should be about 0.5s\n",
    "                fade_samples = math.ceil(0.1 * sample_rate)\n",
    "                if fade_samples > new_len: fade_samples = new_len\n",
    "\n",
    "                # Apply fade\n",
    "                samples_to_add = fade(\n",
    "                    array = samples_to_add,\n",
    "                    fade_len = fade_samples,\n",
    "                    start_amp = 1,\n",
    "                )\n",
    "            \n",
    "            # Zero pad\n",
    "            samples_to_add = np.pad(\n",
    "                samples_to_add,\n",
    "                (0, discrepancy),\n",
    "                constant_values = 0\n",
    "            )\n",
    "    else:\n",
    "        samples_to_add = samples_new[:original_len]\n",
    "        \n",
    "    return np.add(samples_original, samples_to_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test fade & wraparound on audio-like numpy arrays\n",
    "nowrap_nofade = sum_samples(\n",
    "    samples_original = np.array((1., 1., 500.)),\n",
    "    samples_new = np.array((10., 11.)),\n",
    "    sample_rate = 1,\n",
    "    wraparound_fill = False,\n",
    "    fade_out = False\n",
    ")\n",
    "npt.assert_array_equal(nowrap_nofade, np.array([11., 12.,  500.]))\n",
    "\n",
    "nowrap_fade = sum_samples(\n",
    "    samples_original = np.array((1., 1., 1., 500.)),\n",
    "    samples_new = np.array((10., 10.)),\n",
    "    sample_rate = 1,\n",
    "    wraparound_fill = False,\n",
    "    fade_out = True\n",
    ")\n",
    "npt.assert_array_equal(nowrap_fade, np.array([ 11.,   1.,   1., 500.]))\n",
    "\n",
    "wrap_nofade = sum_samples(\n",
    "    samples_original = np.array((1., 1., 500.)),\n",
    "    samples_new = np.array((10., 11.)),\n",
    "    sample_rate = 1,\n",
    "    wraparound_fill = True,\n",
    "    fade_out = False\n",
    ")\n",
    "npt.assert_array_equal(wrap_nofade, np.array([11., 12.,  510.]))\n",
    "\n",
    "# Same behavior as wrap_nofade\n",
    "wrap_fade = sum_samples(\n",
    "    samples_original = np.array((1., 1., 500.)),\n",
    "    samples_new = np.array((10., 11.)),\n",
    "    sample_rate = 1,\n",
    "    wraparound_fill = True,\n",
    "    fade_out = True\n",
    ")\n",
    "npt.assert_array_equal(wrap_nofade, np.array([11., 12.,  510.]))\n",
    "\n",
    "\n",
    "# Test on actual audio without fade or wraparound\n",
    "samples, sample_rate = librosa.load('../tests/1min.wav')\n",
    "samples_original = samples[:22050]\n",
    "samples_new = cyclic_shift(samples_original)[:11025]\n",
    "\n",
    "summed = sum_samples(\n",
    "    samples_original = samples_original,\n",
    "    samples_new = samples_new,\n",
    "    sample_rate = sample_rate,\n",
    "    wraparound_fill = False,\n",
    "    fade_out = False)\n",
    "\n",
    "true_summed = np.add(samples_original, np.pad(samples_new, (0, 11025), constant_values=0))\n",
    "npt.assert_array_equal(summed, true_summed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function, label combiner: `sum_labels()`  (not implemented yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement\n",
    "def sum_labels(labels_original, labels_new):\n",
    "    raise NotImplementedError('Label combining is not implemented')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function, select audio chunks: `select_chunk()` (not implemented yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement\n",
    "def select_chunk(chunk_source):\n",
    "    raise NotImplementedError('Random chunk selection is not implemented yet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main function: `sum_chunks()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_chunks(\n",
    "    main_chunk_samples,\n",
    "    main_chunk_labels,\n",
    "    new_chunk_source\n",
    "):\n",
    "    '''\n",
    "    Add random audio to a chunk\n",
    "    \n",
    "    Grab a random number of chunks, from 0 to 4, \n",
    "    randomize their signal amplitude (multiply\n",
    "    by a random number from 0 to 1), and add \n",
    "    the chunks to the audio.\n",
    "    \n",
    "    Args:\n",
    "        main_chunk_samples (np.array): array of\n",
    "            samples from the main chunk to have\n",
    "            audio added to it\n",
    "        main_chunk_labels (?): labels, path to \n",
    "            spreadsheet of labels, etc. #TODO\n",
    "        new_chunk_source (?): labels, path to \n",
    "            folder containing lots of audio, etc. #TODO\n",
    "    '''\n",
    "    \n",
    "    chunks_to_add = 0\n",
    "    if random.random() < 0.5:\n",
    "        chunks_to_add += 1\n",
    "        if random.random() < 0.4:\n",
    "            chunks_to_add += 1\n",
    "            if random.random() < 0.3:\n",
    "                chunks_to_add += 1\n",
    "                if random.random() < 0.2:\n",
    "                    chunks_to_add += 1\n",
    "    \n",
    "    # Iteratively combine chunks and labels\n",
    "    for _ in range(chunks_to_add):\n",
    "        # Randomly grab chunk from source\n",
    "        new_chunk_samples, new_chunk_rate, new_chunk_labels = select_chunk(new_chunk_source)\n",
    "        \n",
    "        # Randomly change amplitude of chunk\n",
    "        amp_modifier = random.randrange(0, 1) # TODO: not sure if this has the intended effect\n",
    "        np.multiply(np.array([1, 2, 3]), amp_modifier)\n",
    "        \n",
    "        # Add chunks together\n",
    "        summed_chunks = sum_chunks(\n",
    "            samples_original = main_chunk_samples,\n",
    "            samples_new = new_chunk_samples,\n",
    "            sample_rate = new_chunk_rate,\n",
    "            wraparound_fill = False,\n",
    "            fade_out = False\n",
    "        )\n",
    "        \n",
    "        summed_labels = sum_labels(label)\n",
    "    \n",
    "    return summed_chunks, summed_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# From https://www.agiliq.com/notebook/yanny-or-laurel.html\n",
    "def display_mel_spectrogram(y, sr):\n",
    "    S = librosa.feature.melspectrogram(y, sr=sr, n_mels=128)\n",
    "\n",
    "    # Convert to log scale (dB)\n",
    "    log_S = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "    # Make a new figure\n",
    "    plt.figure(figsize=(12,4))\n",
    "\n",
    "    # Display the spectrogram on a mel scale\n",
    "    # sample rate and hop length parameters are used to render the time axis\n",
    "    librosa.display.specshow(log_S, sr=sr, x_axis='time', y_axis='mel')\n",
    "\n",
    "    # draw a color bar\n",
    "    plt.colorbar(format='%+02.0f dB')\n",
    "\n",
    "    # Make the figure layout compact\n",
    "    plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
