{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import audio\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, sr = librosa.load('../tests/silence_10s.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunk extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function: `wraparound_extract()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wraparound_extract(original, begin, length):\n",
    "    '''\n",
    "    Extracts elements from numpy.array in a \"wraparound\" fashion\n",
    "    \n",
    "    Extracts a certain number of elements from \n",
    "    a numpy.array starting at a certain position.\n",
    "    If the chosen position and length go\n",
    "    past the end of the array, the extraction\n",
    "    \"wraps around\" to the beginning of the numpy.array\n",
    "    as many times as necessary. For instance:\n",
    "    \n",
    "    wraparound_extract(\n",
    "        original = [0, 5, 10],\n",
    "        begin = 1, \n",
    "        length = 7) -> [5, 10, 0, 5, 10, 0, 5]\n",
    "    \n",
    "    Args:\n",
    "        original (np.array): the original array \n",
    "        begin (int): beginning position to extract\n",
    "        length (int): number of elements to extract\n",
    "    '''\n",
    "\n",
    "    # Get `head`: the array after the beginning position\n",
    "    assert(type(original) == np.ndarray)\n",
    "    len_original = original.shape[0]\n",
    "    begin = begin % len_original\n",
    "    head = original[begin:]\n",
    "    len_head = head.shape[0]\n",
    "\n",
    "    # Number of elements we require for full wrap-around\n",
    "    wrap_needed = length - len_head\n",
    "\n",
    "    # Generate the desired list, wrapped if necessary\n",
    "    if wrap_needed > 0:\n",
    "        repeats = np.tile(original, int(wrap_needed/len_original))\n",
    "        tail = np.array(original[ : (wrap_needed % len_original)])\n",
    "        desired_list = np.concatenate((head, repeats, tail))\n",
    "    else:\n",
    "        desired_list = original[begin:begin+length]\n",
    "    \n",
    "    #print(desired_list)\n",
    "    return desired_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests of `wraparound_extract()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.testing as npt\n",
    "\n",
    "# test zero beginning, not getting to end of original array\n",
    "npt.assert_array_equal(wraparound_extract(original = np.array([0, 1]), begin = 0, length = 1), np.array([0]))\n",
    "\n",
    "# test zero beginning, not getting to end of original array\n",
    "npt.assert_array_equal(wraparound_extract(original = np.array([0, 1]), begin = 0, length = 2), np.array([0, 1]))\n",
    "\n",
    "# test zero beginning, not wrapping\n",
    "npt.assert_array_equal(wraparound_extract(original = np.array([0, 1]), begin = 0, length = 2), np.array([0, 1]))\n",
    "\n",
    "# test zero beginning, wrapping around\n",
    "npt.assert_array_equal(wraparound_extract(original = np.array([0, 1]), begin = 0, length = 3), np.array([0, 1, 0]))\n",
    "\n",
    "# test nonzero beginning, not wrapping\n",
    "npt.assert_array_equal(wraparound_extract(original = np.array([0, 1]), begin = 1, length = 1), np.array([1]))\n",
    "\n",
    "# test nonzero beginning, wrapping around\n",
    "npt.assert_array_equal(wraparound_extract(original = np.array([0, 1]), begin = 1, length = 3), np.array([1, 0, 1]))\n",
    "\n",
    "# test multiwrap\n",
    "npt.assert_array_equal(wraparound_extract(original = np.array([0, 1]), begin = 1, length = 10), np.array([1, 0, 1, 0, 1, 0, 1, 0, 1, 0]))\n",
    "\n",
    "# test wrapping around beginning\n",
    "npt.assert_array_equal(wraparound_extract(original = np.array([0, 1]), begin = 5, length = 3), np.array([1, 0, 1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main function: `get_chunk()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.1611704e-06,  1.2375080e-05, -1.8404073e-05, ...,\n",
       "        1.4923733e-05, -2.8538039e-05,  6.9725588e-06], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_chunk(\n",
    "    samples, \n",
    "    sample_rate,\n",
    "    start_position = None, # randomize start position\n",
    "    duration = 5, # 5 seconds\n",
    "    duration_jitter = 0.5, #jitter duration +- 0.5s\n",
    "    chance_random_skip = 0.3 #randomly skip 30% of the time\n",
    "):\n",
    "    '''\n",
    "    Extracts chunk of audio with some augmentation\n",
    "    \n",
    "    Extracts samples of audio from a master list\n",
    "    of samples. \n",
    "    \n",
    "    Available data augmentation options include:\n",
    "        - selecting a position to start extracting from\n",
    "          or allowing function to randomly choose start\n",
    "        - selecting duration of chunk and allowing\n",
    "          for random jitter of duration\n",
    "        - randomly skipping some number of samples from\n",
    "          0 to the length of the chunk\n",
    "    \n",
    "    If the chunk to be extracted reaches the end of the\n",
    "    samples, the chunk will \"wrap around\" and start\n",
    "    reading from the beginning of the samples.\n",
    "    \n",
    "    Args:\n",
    "        samples (numpy.array): audio samples loaded\n",
    "            by librosa.load or audio.load\n",
    "        sample_rate (int or float): sample rate of `samples`\n",
    "        start_position (int): position in the file to start\n",
    "            extracting samples from. If None, the start position \n",
    "            is chosen randomly\n",
    "        duration (float): desired duration, in seconds, \n",
    "            of chunk to extract\n",
    "        duration_jitter (float): if this value is not 0,\n",
    "            the duration of the chunk extracted will \n",
    "            be randomly selected from the range \n",
    "            (duration - duration_jitter, duration + duration_jitter)\n",
    "        chance_random_skip (float between 0 and 1):\n",
    "            percent chance of random skipping. In a random skip,\n",
    "            a position within the chunk will be randomly\n",
    "            selected, and from that position in the \n",
    "            audio file, a random number of samples will \n",
    "            be skipped. The number of samples skipped is between\n",
    "            0 and the number of samples in the entire chunk\n",
    "    \n",
    "    Returns:\n",
    "        samples\n",
    "    '''\n",
    "    \n",
    "    # Get a random start position\n",
    "    num_samples = len(samples)\n",
    "    if not start_position:\n",
    "        start_position = random.randint(0, num_samples)\n",
    "\n",
    "    # Convert seconds to samples\n",
    "    seconds_to_extract = duration + random.uniform(-duration_jitter, duration_jitter)\n",
    "    samples_to_extract = int(seconds_to_extract * sample_rate)\n",
    "    \n",
    "    # Get chunks with skip in the middle with probability = chance_random_skip\n",
    "    if random.random() < chance_random_skip:\n",
    "        position_to_skip = random.randint(0, samples_to_extract)\n",
    "        amount_to_skip = random.randint(0, samples_to_extract)\n",
    "\n",
    "        chunk_1_start = start_position\n",
    "        chunk_1_end = chunk_1_start + position_to_skip\n",
    "        chunk_2_start = chunk_1_end + amount_to_skip\n",
    "        chunk_2_end = chunk_1_start + (samples_to_extract - position_to_skip)\n",
    "        \n",
    "        chunk_1 = wraparound_extract(samples, chunk_1_start, chunk_1_end)\n",
    "        chunk_2 = wraparound_extract(samples, chunk_2_start, chunk_2_end)\n",
    "        chunk = np.concatenate((chunk_1, chunk_2))\n",
    "    \n",
    "    # Otherwise get contiguous chunk\n",
    "    else:\n",
    "        chunk = wraparound_extract(samples, start_position, samples_to_extract) \n",
    "        \n",
    "    \n",
    "    return chunk\n",
    "    \n",
    "\n",
    "get_chunk(samples = samples, sample_rate = sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: tests for `get_chunk()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cyclic shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cyclic_shift(array, split_point = None):\n",
    "    '''\n",
    "    Shift array cyclicly by a random amount\n",
    "    \n",
    "    Shift array cyclicly by a random amount. Equivalent to\n",
    "    splitting array into two parts at a random element, then\n",
    "    switching the order of the parts.\n",
    "    \n",
    "    Args: \n",
    "        array (np.array): 1D-array to be split\n",
    "        split_point (float): float in (0, 1) describing\n",
    "            where in array to split -- for testing purposes.\n",
    "            For stochastic splitting, leave as None.\n",
    "    \n",
    "    Returns:\n",
    "        shifted_array: shifted array\n",
    "    '''\n",
    "    \n",
    "    assert(type(array) == np.ndarray)\n",
    "    length = array.shape[0]\n",
    "    \n",
    "    # Stochastic split point, or split point by floor of split_point * length of array\n",
    "    if not split_point: split_point = random.randint(0, length)\n",
    "    else: split_point = int(split_point * length)\n",
    "    \n",
    "    return np.concatenate((array[split_point:], array[:split_point]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test random splitting\n",
    "random.seed(100)\n",
    "npt.assert_array_equal(cyclic_shift(np.array((0, 1, 2, 3, 4, 5, 6, 7))), np.array([2, 3, 4, 5, 6, 7, 0, 1]))\n",
    "\n",
    "# Test deterministic splitting\n",
    "npt.assert_array_equal(cyclic_shift(np.array([0, 1, 2]), split_point=0.5), np.array([1, 2, 0]))\n",
    "\n",
    "# Test deterministic splitting\n",
    "npt.assert_array_equal(cyclic_shift(np.array([0, 1, 2, 3]), split_point=0.5), np.array([2, 3, 0, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divided-samples augmentations: time & freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function to divide samples randomly `divide_samples()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_samples(\n",
    "    samples,\n",
    "    sample_rate,\n",
    "    low_duration = 0.5,\n",
    "    high_duration = 5\n",
    "):\n",
    "    '''\n",
    "    Divide audio samples into random-sized segments\n",
    "    \n",
    "    Divide audio samples into random-sized segments\n",
    "    between the desired durations. The number\n",
    "    of segments is not deterministic.\n",
    "    \n",
    "    Args:\n",
    "        samples (np.ndarray): 1d array of samples\n",
    "        sample_rate (int or float): sample rate of samples\n",
    "        low_duration (float): minimum duration\n",
    "            in seconds of any segment\n",
    "        high_duration (float): maximum duration\n",
    "            in seconds of any segment\n",
    "    \n",
    "    Returns:\n",
    "        segments, list of sample lists\n",
    "    '''\n",
    "    \n",
    "    min_chunk = int(low_duration * sample_rate)\n",
    "    max_chunk = int(high_duration * sample_rate)\n",
    "    \n",
    "    samples_to_take = samples.copy()\n",
    "    \n",
    "    segments = []\n",
    "    \n",
    "    while samples_to_take.shape[0]:\n",
    "        seg_size = random.randint(min_chunk, max_chunk)\n",
    "        segment, samples_to_take = np.split(samples_to_take, [seg_size])\n",
    "        segments.append(segment)\n",
    "    \n",
    "    return segments\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test chunk division at set amount\n",
    "array0 = np.array([0, 0, 0])\n",
    "array1 = np.array([1, 1, 1])\n",
    "array2 = np.array([2])\n",
    "all_arrays = (array0, array1, array2)\n",
    "cat_arrays = np.concatenate(all_arrays)\n",
    "results = divide_samples(cat_arrays, sample_rate=1, low_duration=3, high_duration=3)\n",
    "for idx, result in enumerate(results):\n",
    "    npt.assert_array_equal(result, all_arrays[idx])\n",
    "    \n",
    "# Test random chunk division\n",
    "random.seed(333)\n",
    "# Predetermined results with random.seed(333)\n",
    "predetermined = [np.array([0, 1, 2, 3, 4, 5, 6, 7]), np.array([8, 9])]\n",
    "results = divide_samples(np.array(range(10)), sample_rate=1, low_duration=0, high_duration=10)\n",
    "for idx, result in enumerate(results):\n",
    "    npt.assert_array_equal(result, predetermined[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function to concatenate divisions: `combine_samples()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_samples(divided):\n",
    "    '''\n",
    "    Recombine divided sample arrays\n",
    "    \n",
    "    Combine divided sample arrays back into a \n",
    "    single array, perhaps after each division\n",
    "    has been modified by pitch shifting, time stretching, etc.\n",
    "    \n",
    "    Args:\n",
    "        divided (list of np.ndarrays): list of sample arrays\n",
    "            divided by divide_samples()\n",
    "    \n",
    "    Returns:\n",
    "        sample arrays concatenated back into a single array\n",
    "    '''\n",
    "    \n",
    "    return np.concatenate(divided)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test that divided samples can be recombined successfully\n",
    "samples, sr = librosa.load('../tests/silence_10s.mp3')\n",
    "divided = divide_samples(samples, sample_rate=sr, low_duration=0.5, high_duration=4)\n",
    "npt.assert_array_equal(combine_samples(divided), samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time stretch the divisions `time_stretch_divisions()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_stretch_divisions(\n",
    "    divisions,\n",
    "    chance_per_division = 0.50,\n",
    "    mean_stretch = 1,\n",
    "    sd_stretch = 0.05\n",
    "):\n",
    "    '''\n",
    "    Time stretch divisions\n",
    "    \n",
    "    Given a list of np.ndarrays, each np.ndarray representing\n",
    "    audio samples, time stretch each array with some probability. \n",
    "    \n",
    "    Args\"\n",
    "        divisions (list of np.ndarrays): list of np.ndarrays\n",
    "            where each element of the list is samples from\n",
    "            an audio file. A list of divisions can be generated \n",
    "            with helper functions in this module\n",
    "        chance_per_division (float between 0 and 1): for\n",
    "            each division, the chance it will be time-stretched\n",
    "        mean_stretch (float): the mean stretch multiplier.\n",
    "            == 1 is no stretch; > 1 is sped up, < 1 is slowed down\n",
    "        sd_stretch (float > 0): the sd of the stretch \n",
    "            distribution. \n",
    "    \n",
    "    Returns:\n",
    "        stretched_divisions, time-stretched divisions\n",
    "    '''\n",
    "    stretched_divisions = []\n",
    "    \n",
    "    for d in divisions:\n",
    "        if random.random() < chance_per_division:\n",
    "            stretch_factor = np.random.normal(\n",
    "                loc = mean_stretch,\n",
    "                scale = sd_stretch)\n",
    "            stretched_d = librosa.effects.time_stretch(y = d, rate = stretch_factor)\n",
    "            stretched_divisions.append(stretched_d)\n",
    "        else:\n",
    "            stretched_divisions.append(d)\n",
    "    \n",
    "    return stretched_divisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-3.1739323e-06, -1.4155360e-05, -8.0013604e-07, ...,\n",
      "        5.1449551e-06, -4.9028572e-06,  2.2106809e-05], dtype=float32), array([-2.2841281e-05,  2.0544954e-05, -1.4502888e-05, ...,\n",
      "       -1.6800034e-06, -1.1951680e-05,  5.1101538e-06], dtype=float32), array([ 3.8452645e-06, -1.3770463e-05,  2.2396178e-05, ...,\n",
      "       -2.1374344e-06,  1.4918282e-05, -6.5673667e-06], dtype=float32), array([ 2.7424021e-05, -3.0760748e-05, -7.1096433e-06, ...,\n",
      "        2.3299851e-06, -1.1209999e-06, -1.9890509e-05], dtype=float32)]\n",
      "\n",
      "[array([-3.2555515e-06, -1.4118433e-05, -7.7664885e-07, ...,\n",
      "        3.2824366e-06,  8.8522086e-07, -1.3140799e-07], dtype=float32), array([-2.2841281e-05,  2.0544954e-05, -1.4502888e-05, ...,\n",
      "       -1.6800034e-06, -1.1951680e-05,  5.1101538e-06], dtype=float32), array([ 4.0471245e-06, -1.3970946e-05,  2.2610662e-05, ...,\n",
      "        1.1275706e-06,  7.0119158e-06, -3.3273775e-06], dtype=float32), array([ 2.7424021e-05, -3.0760748e-05, -7.1096433e-06, ...,\n",
      "        2.3299851e-06, -1.1209999e-06, -1.9890509e-05], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "divs = divide_samples(\n",
    "    samples = samples,\n",
    "    sample_rate = sr,\n",
    "    low_duration = 0.5,\n",
    "    high_duration = 4)\n",
    "print(divs)\n",
    "print()\n",
    "print(time_stretch_divisions(divs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency shift the divisions `pitch_shift_divisions()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pitch_shift_divisions(\n",
    "    divisions,\n",
    "    sample_rate,\n",
    "    chance_per_division = 0.40,\n",
    "    mean_shift = 0,\n",
    "    sd_shift = 0.25\n",
    "):\n",
    "    '''\n",
    "    Time stretch divisions\n",
    "    \n",
    "    Given a list of np.ndarrays, each np.ndarray representing\n",
    "    audio samples, pitch-shift each array with some probability. \n",
    "    The mean_shift and sd_shift should be given in \"fractional\n",
    "    half-steps,\" e.g. 0.25 = 1/4th of a half-step = 25 cents.\n",
    "    \n",
    "    Args:\n",
    "        divisions (list of np.ndarrays): list of np.ndarrays\n",
    "            where each element of the list is samples from\n",
    "            an audio file. A list of divisions can be generated \n",
    "            with helper functions in this module\n",
    "        sample_rate (int or float): sample rate of all divisions\n",
    "        chance_per_division (float between 0 and 1): for\n",
    "            each division, the chance it will be time-stretched\n",
    "        mean_shift (float): the mean pitch shift in (fractional) half-steps\n",
    "            == 0 is no shift; > 0 is shift up; < 1 is shift down\n",
    "        sd_shift (float > 0): the sd of the shift \n",
    "            distribution in cents\n",
    "    \n",
    "    Returns:\n",
    "        shifted_divisions, pitch-shifted divisions\n",
    "    '''\n",
    "    shifted_divisions = []\n",
    "    \n",
    "    for d in divisions:\n",
    "        if random.random() < chance_per_division:\n",
    "            shift_factor = np.random.normal(\n",
    "                loc = mean_shift,\n",
    "                scale = sd_shift)\n",
    "            shifted_d = librosa.effects.pitch_shift(\n",
    "                y = d,\n",
    "                sr = sample_rate,\n",
    "                n_steps = shift_factor)\n",
    "            shifted_divisions.append(shifted_d)\n",
    "        else:\n",
    "            shifted_divisions.append(d)\n",
    "    \n",
    "    return shifted_divisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-3.1739323e-06, -1.4155360e-05, -8.0013604e-07, ...,\n",
      "       -3.3414140e-06, -1.6852617e-05,  2.4009105e-05], dtype=float32), array([-1.4325174e-05,  5.6216527e-06, -1.4833859e-06, ...,\n",
      "        8.9725813e-07,  1.0267116e-05,  1.3058184e-06], dtype=float32), array([-1.0680385e-06,  2.3093113e-05, -4.1025992e-06, ...,\n",
      "       -4.4186345e-06,  7.7120267e-06, -7.1442760e-06], dtype=float32), array([ 1.2961112e-05, -1.9446245e-05,  1.8699564e-05, ...,\n",
      "       -1.0537792e-05,  1.7019402e-05, -1.0489415e-05], dtype=float32), array([-1.1029069e-05,  2.3416687e-05, -1.8281529e-05, ...,\n",
      "        2.0505417e-05, -3.3454414e-06, -9.0473446e-07], dtype=float32), array([ 3.24280541e-06,  6.52213475e-06,  1.37935285e-05, ...,\n",
      "        2.32998514e-06, -1.12099985e-06, -1.98905091e-05], dtype=float32)]\n",
      "\n",
      "[array([-3.1739323e-06, -1.4155360e-05, -8.0013604e-07, ...,\n",
      "       -3.3414140e-06, -1.6852617e-05,  2.4009105e-05], dtype=float32), array([-1.4325174e-05,  5.6216527e-06, -1.4833859e-06, ...,\n",
      "        8.9725813e-07,  1.0267116e-05,  1.3058184e-06], dtype=float32), array([-1.0680385e-06,  2.3093113e-05, -4.1025992e-06, ...,\n",
      "       -4.4186345e-06,  7.7120267e-06, -7.1442760e-06], dtype=float32), array([ 1.2961112e-05, -1.9446245e-05,  1.8699564e-05, ...,\n",
      "       -1.0537792e-05,  1.7019402e-05, -1.0489415e-05], dtype=float32), array([-1.1029069e-05,  2.3416687e-05, -1.8281529e-05, ...,\n",
      "        2.0505417e-05, -3.3454414e-06, -9.0473446e-07], dtype=float32), array([ 2.7105257e-06,  6.8608324e-06,  1.3547601e-05, ...,\n",
      "       -3.5417329e-06,  1.5896718e-05, -8.5129750e-06], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "divs = divide_samples(\n",
    "    samples = samples,\n",
    "    sample_rate = sr,\n",
    "    low_duration = 0.5,\n",
    "    high_duration = 4)\n",
    "print(divs)\n",
    "print()\n",
    "print(pitch_shift_divisions(divs, sample_rate = sr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
