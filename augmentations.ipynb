{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import audio\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, sr = librosa.load('../tests/silence_10s.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunk extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function: `wraparound_extract()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wraparound_extract(original, begin, length):\n",
    "    '''\n",
    "    Extracts elements from numpy.array in a \"wraparound\" fashion\n",
    "    \n",
    "    Extracts a certain number of elements from \n",
    "    a numpy.array starting at a certain position.\n",
    "    If the chosen position and length go\n",
    "    past the end of the array, the extraction\n",
    "    \"wraps around\" to the beginning of the numpy.array\n",
    "    as many times as necessary. For instance:\n",
    "    \n",
    "    wraparound_extract(\n",
    "        original = [0, 5, 10],\n",
    "        begin = 1, \n",
    "        length = 7) -> [5, 10, 0, 5, 10, 0, 5]\n",
    "    \n",
    "    Args:\n",
    "        original (np.array): the original array \n",
    "        begin (int): beginning position to extract\n",
    "        length (int): number of elements to extract\n",
    "    '''\n",
    "\n",
    "    # Get `head`: the array after the beginning position\n",
    "    assert(type(original) == np.ndarray)\n",
    "    len_original = original.shape[0]\n",
    "    begin = begin % len_original\n",
    "    head = original[begin:]\n",
    "    len_head = head.shape[0]\n",
    "\n",
    "    # Number of elements we require for full wrap-around\n",
    "    wrap_needed = length - len_head\n",
    "\n",
    "    # Generate the desired list, wrapped if necessary\n",
    "    if wrap_needed > 0:\n",
    "        repeats = np.tile(original, int(wrap_needed/len_original))\n",
    "        tail = np.array(original[ : (wrap_needed % len_original)])\n",
    "        desired_list = np.concatenate((head, repeats, tail))\n",
    "    else:\n",
    "        desired_list = original[begin:begin+length]\n",
    "    \n",
    "    #print(desired_list)\n",
    "    return desired_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests of `wraparound_extract()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.testing as npt\n",
    "\n",
    "# test zero beginning, not getting to end of original array\n",
    "npt.assert_array_equal(wraparound_extract(original = np.array([0, 1]), begin = 0, length = 1), np.array([0]))\n",
    "\n",
    "# test zero beginning, not getting to end of original array\n",
    "npt.assert_array_equal(wraparound_extract(original = np.array([0, 1]), begin = 0, length = 2), np.array([0, 1]))\n",
    "\n",
    "# test zero beginning, not wrapping\n",
    "npt.assert_array_equal(wraparound_extract(original = np.array([0, 1]), begin = 0, length = 2), np.array([0, 1]))\n",
    "\n",
    "# test zero beginning, wrapping around\n",
    "npt.assert_array_equal(wraparound_extract(original = np.array([0, 1]), begin = 0, length = 3), np.array([0, 1, 0]))\n",
    "\n",
    "# test nonzero beginning, not wrapping\n",
    "npt.assert_array_equal(wraparound_extract(original = np.array([0, 1]), begin = 1, length = 1), np.array([1]))\n",
    "\n",
    "# test nonzero beginning, wrapping around\n",
    "npt.assert_array_equal(wraparound_extract(original = np.array([0, 1]), begin = 1, length = 3), np.array([1, 0, 1]))\n",
    "\n",
    "# test multiwrap\n",
    "npt.assert_array_equal(wraparound_extract(original = np.array([0, 1]), begin = 1, length = 10), np.array([1, 0, 1, 0, 1, 0, 1, 0, 1, 0]))\n",
    "\n",
    "# test wrapping around beginning\n",
    "npt.assert_array_equal(wraparound_extract(original = np.array([0, 1]), begin = 5, length = 3), np.array([1, 0, 1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main function: `get_chunk()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.4658695e-05,  4.3753503e-06,  5.9822269e-06, ...,\n",
       "        6.4597469e-07, -5.6203603e-06,  2.1704989e-06], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_chunk(\n",
    "    samples, \n",
    "    sample_rate,\n",
    "    start_position = None, # randomize start position\n",
    "    duration = 5, # 5 seconds\n",
    "    duration_jitter = 0.5, #jitter duration +- 0.5s\n",
    "    chance_random_skip = 0.3 #randomly skip 30% of the time\n",
    "):\n",
    "    '''\n",
    "    Extracts chunk of audio with some augmentation\n",
    "    \n",
    "    Extracts samples of audio from a master list\n",
    "    of samples. \n",
    "    \n",
    "    Available data augmentation options include:\n",
    "        - selecting a position to start extracting from\n",
    "          or allowing function to randomly choose start\n",
    "        - selecting duration of chunk and allowing\n",
    "          for random jitter of duration\n",
    "        - randomly skipping some number of samples from\n",
    "          0 to the length of the chunk\n",
    "    \n",
    "    If the chunk to be extracted reaches the end of the\n",
    "    samples, the chunk will \"wrap around\" and start\n",
    "    reading from the beginning of the samples.\n",
    "    \n",
    "    Args\n",
    "        samples (numpy.array) - audio samples loaded\n",
    "            by librosa.load or audio.load\n",
    "        sample_rate (int) - sample rate of `samples`\n",
    "        start_position (int) - position in the file to start\n",
    "            extracting samples from. If None, the start position \n",
    "            is chosen randomly\n",
    "        duration (float) - desired duration, in seconds, \n",
    "            of chunk to extract\n",
    "        duration_jitter (float) - if this value is not 0,\n",
    "            the duration of the chunk extracted will \n",
    "            be randomly selected from the range \n",
    "            (duration - duration_jitter, duration + duration_jitter)\n",
    "        chance_random_skip (float between 0 and 1) - \n",
    "            percent chance of random skipping. In a random skip,\n",
    "            a position within the chunk will be randomly\n",
    "            selected, and from that position in the \n",
    "            audio file, a random number of samples will \n",
    "            be skipped. The number of samples skipped is between\n",
    "            0 and the number of samples in the entire chunk\n",
    "    \n",
    "    Returns\n",
    "        samples\n",
    "    '''\n",
    "    \n",
    "    # Get a random start position\n",
    "    num_samples = len(samples)\n",
    "    if not start_position:\n",
    "        start_position = random.randint(0, num_samples)\n",
    "\n",
    "    # Convert seconds to samples\n",
    "    seconds_to_extract = duration + random.uniform(-duration_jitter, duration_jitter)\n",
    "    samples_to_extract = int(seconds_to_extract * sample_rate)\n",
    "    \n",
    "    # Get chunks with skip in the middle with probability = chance_random_skip\n",
    "    if random.random() < chance_random_skip:\n",
    "        position_to_skip = random.randint(0, samples_to_extract)\n",
    "        amount_to_skip = random.randint(0, samples_to_extract)\n",
    "\n",
    "        chunk_1_start = start_position\n",
    "        chunk_1_end = chunk_1_start + position_to_skip\n",
    "        chunk_2_start = chunk_1_end + amount_to_skip\n",
    "        chunk_2_end = chunk_1_start + (samples_to_extract - position_to_skip)\n",
    "        \n",
    "        chunk_1 = wraparound_extract(samples, chunk_1_start, chunk_1_end)\n",
    "        chunk_2 = wraparound_extract(samples, chunk_2_start, chunk_2_end)\n",
    "        chunk = np.concatenate((chunk_1, chunk_2))\n",
    "    \n",
    "    # Otherwise get contiguous chunk\n",
    "    else:\n",
    "        chunk = wraparound_extract(samples, start_position, samples_to_extract) \n",
    "        \n",
    "    \n",
    "    return chunk\n",
    "    \n",
    "\n",
    "get_chunk(samples = samples, sample_rate = sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: tests for `get_chunk()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cyclic shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cyclic_shift(array, split_point = None):\n",
    "    '''\n",
    "    Shift array cyclicly by a random amount\n",
    "    \n",
    "    Shift array cyclicly by a random amount. Equivalent to\n",
    "    splitting array into two parts at a random element, then\n",
    "    switching the order of the parts.\n",
    "    \n",
    "    Args: \n",
    "        array (np.array): 1D-array to be split\n",
    "        split_point (float): float in (0, 1) describing\n",
    "            where in array to split -- for testing purposes.\n",
    "            For stochastic splitting, leave as None.\n",
    "    \n",
    "    Returns:\n",
    "        shifted_array: shifted array\n",
    "    '''\n",
    "    \n",
    "    assert(type(array) == np.ndarray)\n",
    "    length = array.shape[0]\n",
    "    \n",
    "    # Stochastic split point, or split point by floor of split_point * length of array\n",
    "    if not split_point: split_point = random.randint(0, length)\n",
    "    else: split_point = int(split_point * length)\n",
    "    \n",
    "    return np.concatenate((array[split_point:], array[:split_point]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test random splitting\n",
    "random.seed(100)\n",
    "npt.assert_array_equal(cyclic_shift(np.array((0, 1, 2, 3, 4, 5, 6, 7))), np.array([2, 3, 4, 5, 6, 7, 0, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test deterministic splitting\n",
    "npt.assert_array_equal(cyclic_shift(np.array([0, 1, 2]), split_point=0.5), np.array([1, 2, 0]))\n",
    "\n",
    "# Test deterministic splitting\n",
    "npt.assert_array_equal(cyclic_shift(np.array([0, 1, 2, 3]), split_point=0.5), np.array([2, 3, 0, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divided-samples augmentations: time & freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function to divide samples randomly `divide_samples()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_samples(\n",
    "    samples,\n",
    "    sample_rate,\n",
    "    low_duration = 0.5,\n",
    "    high_duration = 5\n",
    "):\n",
    "    '''\n",
    "    Divide audio samples into random-sized segments\n",
    "    \n",
    "    Divide audio samples into random-sized segments\n",
    "    between the desired durations. The number\n",
    "    of segments is not deterministic.\n",
    "    \n",
    "    Args\n",
    "        samples (np.ndarray): 1d array of samples\n",
    "        sample_rate (int): sample rate of samples\n",
    "        low_duration (float): minimum duration\n",
    "            in seconds of any segment\n",
    "        high_duration (float): maximum duration\n",
    "            in seconds of any segment\n",
    "    \n",
    "    Returns\n",
    "        segments, list of sample lists\n",
    "    '''\n",
    "    \n",
    "    min_chunk = int(low_duration * sample_rate)\n",
    "    max_chunk = int(high_duration * sample_rate)\n",
    "    \n",
    "    samples_to_take = samples.copy()\n",
    "    \n",
    "    segments = []\n",
    "    \n",
    "    while samples_to_take.shape[0]:\n",
    "        seg_size = random.randint(min_chunk, max_chunk)\n",
    "        segment, samples_to_take = np.split(samples_to_take, [seg_size])\n",
    "        segments.append(segment)\n",
    "    \n",
    "    return segments\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test chunk division at set amount\n",
    "array0 = np.array([0, 0, 0])\n",
    "array1 = np.array([1, 1, 1])\n",
    "array2 = np.array([2])\n",
    "all_arrays = (array0, array1, array2)\n",
    "cat_arrays = np.concatenate(all_arrays)\n",
    "results = divide_chunk(cat_arrays, sample_rate=1, low_duration=3, high_duration=3)\n",
    "for idx, result in enumerate(results):\n",
    "    npt.assert_array_equal(result, all_arrays[idx])\n",
    "    \n",
    "# Test random chunk division\n",
    "random.seed(333)\n",
    "# Predetermined results with random.seed(333)\n",
    "predetermined = [np.array([0, 1, 2, 3, 4, 5, 6, 7]), np.array([8, 9])]\n",
    "results = divide_chunk(np.array(range(10)), sample_rate=1, low_duration=0, high_duration=10)\n",
    "for idx, result in enumerate(results):\n",
    "    npt.assert_array_equal(result, predetermined[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function to concatenate divisions: `combine_samples()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_samples(divided):\n",
    "    '''\n",
    "    Combine divided samples back into a single array\n",
    "    '''\n",
    "    \n",
    "    return np.concatenate(divided)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test that divided samples can be recombined successfully\n",
    "samples, sr = librosa.load('../tests/silence_10s.mp3')\n",
    "divided = divide_chunk(samples, sample_rate=sr, low_duration=0.5, high_duration=4)\n",
    "npt.assert_array_equal(combine_samples(divided), samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time stretch the divisions `time_stretch_divisions()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_stretch_divisions(\n",
    "    divisions,\n",
    "    chance_per_division = 0.50,\n",
    "    mean_stretch = 1,\n",
    "    sd_stretch = 0.05\n",
    "):\n",
    "    '''\n",
    "    Time stretch divisions\n",
    "    \n",
    "    Given a list of np.ndarrays, each np.ndarray representing\n",
    "    audio samples, stretch each array with some probability. \n",
    "    \n",
    "    Args\n",
    "        divisions (list of np.ndarrays) - list of np.ndarrays\n",
    "            where each element of the list is samples from\n",
    "            an audio file. A list of divisions can be generated \n",
    "            with helper functions in this module\n",
    "        chance_per_division (float between 0 and 1) - for\n",
    "            each division, the chance it will be time-stretched\n",
    "        mean_stretch (float) - the mean stretch multiplier.\n",
    "            == 1 is no stretch; > 1 is sped up, < 1 is slowed down\n",
    "        sd_stretch (float > 0) - the sd of the stretch \n",
    "            distribution. \n",
    "    \n",
    "    Returns\n",
    "        stretched_divisions, time-stretched divisions\n",
    "    '''\n",
    "    stretched_divisions = []\n",
    "    \n",
    "    for d in divisions:\n",
    "        if random.random() < chance_per_division:\n",
    "            stretch_factor = np.random.normal(\n",
    "                loc = mean_stretch,\n",
    "                scale = sd_stretch)\n",
    "            stretched_d = librosa.effects.time_stretch(y = d, rate = stretch_factor)\n",
    "            stretched_divisions.append(stretched_d)\n",
    "        else:\n",
    "            stretched_divisions.append(d)\n",
    "    \n",
    "    return stretched_divisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-3.1739323e-06, -1.4155360e-05, -8.0013604e-07, ...,\n",
      "       -1.1481586e-05,  6.8212121e-06,  1.0021004e-05], dtype=float32), array([-3.8107450e-05,  3.2519703e-05, -7.2488378e-06, ...,\n",
      "       -4.7965218e-06, -5.5835485e-06,  1.4950513e-05], dtype=float32), array([-1.8977646e-05,  1.4777322e-05, -9.8069831e-06, ...,\n",
      "       -6.1632509e-06,  9.4395991e-06, -5.3064232e-06], dtype=float32), array([-1.9714490e-07, -1.1566351e-05,  1.6784650e-06, ...,\n",
      "        2.3299851e-06, -1.1209999e-06, -1.9890509e-05], dtype=float32)]\n",
      "\n",
      "[array([-3.1739323e-06, -1.4155360e-05, -8.0013604e-07, ...,\n",
      "       -1.1481586e-05,  6.8212121e-06,  1.0021004e-05], dtype=float32), array([-3.7972175e-05,  3.2426495e-05, -7.2842754e-06, ...,\n",
      "       -4.0658415e-06,  4.0835298e-06,  3.5917142e-06], dtype=float32), array([-1.9036903e-05,  1.4823869e-05, -9.8147520e-06, ...,\n",
      "       -3.2932824e-06,  6.1536948e-06,  1.0869603e-07], dtype=float32), array([-1.9714490e-07, -1.1566351e-05,  1.6784650e-06, ...,\n",
      "        2.3299851e-06, -1.1209999e-06, -1.9890509e-05], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "divs = divide_samples(\n",
    "    samples = samples,\n",
    "    sample_rate = sr,\n",
    "    low_duration = 0.5,\n",
    "    high_duration = 4)\n",
    "print(divs)\n",
    "print()\n",
    "print(time_stretch_divisions(divs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency shift the divisions `pitch_shift_divisions()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pitch_shift_divisions(\n",
    "    divisions,\n",
    "    sample_rate,\n",
    "    chance_per_division = 0.40,\n",
    "    mean_shift = 0,\n",
    "    sd_shift = 0.25\n",
    "):\n",
    "    '''\n",
    "    Time stretch divisions\n",
    "    \n",
    "    Given a list of np.ndarrays, each np.ndarray representing\n",
    "    audio samples, pitch-shift each array with some probability. \n",
    "    The mean_shift and sd_shift should be given in \"fractional\n",
    "    half-steps,\" e.g. 0.25 = 1/4th of a half-step = 25 cents.\n",
    "    \n",
    "    Args\n",
    "        divisions (list of np.ndarrays) - list of np.ndarrays\n",
    "            where each element of the list is samples from\n",
    "            an audio file. A list of divisions can be generated \n",
    "            with helper functions in this module\n",
    "        sample_rate (int) - sample rate of all divisions\n",
    "        chance_per_division (float between 0 and 1) - for\n",
    "            each division, the chance it will be time-stretched\n",
    "        mean_shift (float) - the mean pitch shift in (fractional) half-steps\n",
    "            == 0 is no shift; > 0 is shift up; < 1 is shift down\n",
    "        sd_shift (float > 0) - the sd of the shift \n",
    "            distribution in cents\n",
    "    \n",
    "    Returns\n",
    "        shifted_divisions, pitch-shifted divisions\n",
    "    '''\n",
    "    shifted_divisions = []\n",
    "    \n",
    "    for d in divisions:\n",
    "        if random.random() < chance_per_division:\n",
    "            shift_factor = np.random.normal(\n",
    "                loc = mean_shift,\n",
    "                scale = sd_shift)\n",
    "            shifted_d = librosa.effects.pitch_shift(\n",
    "                y = d,\n",
    "                sr = sample_rate,\n",
    "                n_steps = shift_factor)\n",
    "            shifted_divisions.append(shifted_d)\n",
    "        else:\n",
    "            shifted_divisions.append(d)\n",
    "    \n",
    "    return shifted_divisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-3.1739323e-06, -1.4155360e-05, -8.0013604e-07, ...,\n",
      "        6.8143886e-06,  3.1100448e-05, -1.8384324e-05], dtype=float32), array([ 3.9387855e-06,  5.3881701e-07,  2.3175693e-05, ...,\n",
      "        2.1746659e-05, -2.4835585e-05, -1.5028519e-06], dtype=float32), array([ 1.3826174e-05, -1.4743614e-05, -2.8227121e-06, ...,\n",
      "        1.1666191e-06, -6.9062385e-06,  1.3662212e-05], dtype=float32), array([-1.76084395e-05,  1.62241304e-06,  1.51464765e-05, ...,\n",
      "        2.32998514e-06, -1.12099985e-06, -1.98905091e-05], dtype=float32)]\n",
      "\n",
      "[array([-3.1739323e-06, -1.4155360e-05, -8.0013604e-07, ...,\n",
      "        6.8143886e-06,  3.1100448e-05, -1.8384324e-05], dtype=float32), array([ 2.9299094e-06,  8.2540856e-07,  2.2824666e-05, ...,\n",
      "        1.2406320e-05, -4.7489721e-06,  0.0000000e+00], dtype=float32), array([ 1.3826174e-05, -1.4743614e-05, -2.8227121e-06, ...,\n",
      "        1.1666191e-06, -6.9062385e-06,  1.3662212e-05], dtype=float32), array([-1.6713246e-05,  6.2172056e-08,  1.5658659e-05, ...,\n",
      "       -8.8434217e-06,  1.5916128e-05,  0.0000000e+00], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "divs = divide_samples(\n",
    "    samples = samples,\n",
    "    sample_rate = sr,\n",
    "    low_duration = 0.5,\n",
    "    high_duration = 4)\n",
    "print(divs)\n",
    "print()\n",
    "print(pitch_shift_divisions(divs, sample_rate = sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
